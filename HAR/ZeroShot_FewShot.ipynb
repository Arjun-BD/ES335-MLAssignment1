{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to demonstrate Zero shot and Few shot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "#%pip install langchain_groq\n",
    "from langchain_groq.chat_models import ChatGroq\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score, precision_score, confusion_matrix, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groq API and Models \n",
    "Groq_Token = open('..\\\\groqapi.txt', 'r').read()  # Do not share this key with anyone\n",
    "groq_models = {\"llama3-70b\": \"llama3-70b-8192\", \"mixtral\": \"mixtral-8x7b-32768\", \"gemma-7b\": \"gemma-7b-it\",\"llama3.1-70b\":\"llama-3.1-70b-versatile\",\"llama3-8b\":\"llama3-8b-8192\",\"llama3.1-8b\":\"llama-3.1-8b-instant\",\"gemma-9b\":\"gemma2-9b-it\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE : DO NOT SHARE THE API KEY WITH ANYONE. DO NOT COMMIT THE API KEY TO GITHUB.**\n",
    "\n",
    "Always do a sanity check before committing the code to github. If the key is found in the code, you will be penalized with a 0.5 marks deduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero Shot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statement \n",
    "sentence = \"The product quality is amazing but the delivery was delayed. However I am happy with the customer service.\"\n",
    "\n",
    "# System Prompts \n",
    "query = f\"\"\"\n",
    "* You are a sentiment analysis model. \n",
    "* Your task is to analyze the sentiment expressed in the given text and classify it as 'positive', 'negative', or 'neutral'. \n",
    "* Provide the sentiment label and, if necessary, a brief explanation of your reasoning.\n",
    "\n",
    "Sentence: {sentence}\n",
    "\"\"\" \n",
    "\n",
    "# To use Groq LLMs \n",
    "model_name = \"llama3-70b\" # We can choose any model from the groq_models dictionary\n",
    "llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "answer = llm.invoke(query)\n",
    "\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statement \n",
    "sentence = \"The product quality is amazing but the delivery was delayed. However I am happy with the customer service.\"\n",
    "\n",
    "# System Prompts \n",
    "query = f\"\"\"\n",
    "* You are a sentiment analysis model. \n",
    "* Your task is to analyze the sentiment expressed in the given text and classify it as 'positive', 'negative', or 'neutral'. \n",
    "* Provide the sentiment label and, if necessary, a brief explanation of your reasoning.\n",
    "\n",
    "Here are few examples:\n",
    "1. Sentence: 'The customer service was excellent, and I received my order quickly.'\n",
    "Sentiment: Positive\n",
    "\n",
    "2. Sentence: 'The food was bland and the service was slow.'\n",
    "Sentiment: Negative\n",
    "\n",
    "3. Sentence: 'The product is okay, but it's not worth the price.'\n",
    "Sentiment: Neutral\n",
    "\n",
    "Sentence: {sentence}\n",
    "\"\"\" \n",
    "\n",
    "# To use Groq LLMs \n",
    "model_name = \"llama3-70b\" # We can choose any model from the groq_models dictionary\n",
    "llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "answer = llm.invoke(query)\n",
    "\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"C:\\\\Users\\\\Rajeev Wankar\\\\Desktop\\\\Aarsh IITGN\\\\ES335 Machine Learning\\\\main\\\\ES335-MLAssignment1\\\\HAR\\\\UCI HAR Dataset\\\\features.txt\", 'r').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_labels = pd.read_csv(r'../HAR/UCI HAR Dataset/features.txt',sep = '\\\\s+',header=None)\n",
    "dataframeX = pd.read_csv(r'../HAR/UCI HAR Dataset/train/X_train.txt',sep = '\\\\s+',header=None)\n",
    "dataframeY = pd.read_csv(r'../HAR/UCI HAR Dataset/train/y_train.txt',sep = '\\\\s+',header=None)\n",
    "correlation_matrix = dataframeX.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_features(threshold = None):\n",
    "\n",
    "    removals = set()\n",
    "    pairs = product(range(len(correlation_matrix.columns)), repeat=2)\n",
    "\n",
    "    for i, j in pairs:\n",
    "        if i > j:\n",
    "            correlation_value = correlation_matrix.iloc[i, j]\n",
    "            if abs(correlation_value) > threshold and correlation_value != 1:\n",
    "                if i not in removals and j not in removals:\n",
    "                    removals.add(i)\n",
    "\n",
    "    selected_features = [col for col in dataframeX.columns if col not in removals]\n",
    "    return selected_features\n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frs = reduce_features(threshold=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_labels[1].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features = np.array(feature_labels[1].iloc[frs])\n",
    "\n",
    "def example(n):\n",
    "    return dataframeX[frs].iloc[n, :].to_numpy()\n",
    "\n",
    "activity_dic = {1: \"WALKING\", 2: \"WALKING_UPSTAIRS\", 3: \"WALKING_DOWNSTAIRS\", 4: \"SITTING\", 5: \"STANDING\", 6: \"LAYING\"}\n",
    "def label(n):\n",
    "    #print(dataframeY.iloc[n, 0])\n",
    "    return (activity_dic[dataframeY.iloc[n, 0]])\n",
    "    \n",
    "label(10)\n",
    "print(label(100))\n",
    "print(label(234))\n",
    "print(label(134))\n",
    "print(label(135))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(features))\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = {}\n",
    "for i in range(len(dataframeX.columns)):\n",
    "    dictionary[frs[i]] = features[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_labels = [label(i) for i in range(7352)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_dataset = dataframeX[frs]\n",
    "reduced_dataset=reduced_dataset.rename(columns=dictionary)\n",
    "\n",
    "#display(reduced_dataset)\n",
    "reduced_dataset.insert(0, \"Activity_Name\", act_labels)\n",
    "#reduced_dataset[\"Activity_Name\"] = act_labels\n",
    "display(reduced_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_features = [\n",
    "    'tBodyAcc-mean()-X', 'tBodyAcc-mean()-Y', 'tBodyAcc-mean()-Z',\n",
    "    'tBodyAcc-std()-X', 'tBodyAcc-std()-Y', 'tBodyAcc-std()-Z',\n",
    "    'tBodyAccJerk-mean()-X', 'tBodyAccJerk-mean()-Y', 'tBodyAccJerk-mean()-Z',\n",
    "    'tBodyGyro-mean()-X', 'tBodyGyro-mean()-Y', 'tBodyGyro-mean()-Z',\n",
    "    'tBodyGyroJerk-mean()-X', 'tBodyGyroJerk-mean()-Y', 'tBodyGyroJerk-mean()-Z',\n",
    "    'tBodyAccMag-mean()', 'tBodyAccMag-std()', 'tBodyGyroMag-mean()', 'tBodyGyroMag-std()',\n",
    "    'tBodyAccJerkMag-mean()', 'tBodyAccJerkMag-std()', 'tBodyGyroJerkMag-mean()', 'tBodyGyroJerkMag-std()',\n",
    "    'angle(tBodyAccMean,gravity)', 'angle(tBodyAccJerkMean),gravityMean)',\n",
    "    'angle(tBodyGyroMean,gravityMean)', 'angle(tBodyGyroJerkMean,gravityMean)',\n",
    "    'fBodyAcc-meanFreq()-X', 'fBodyAcc-meanFreq()-Y', 'fBodyAcc-meanFreq()-Z',\n",
    "    'fBodyAccJerk-meanFreq()-X', 'fBodyAccJerk-meanFreq()-Y', 'fBodyAccJerk-meanFreq()-Z',\n",
    "    'fBodyGyro-meanFreq()-X', 'fBodyGyro-meanFreq()-Y', 'fBodyGyro-meanFreq()-Z'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_relevants = []\n",
    "for i in relevant_features:\n",
    "    if i in features:\n",
    "        real_relevants.append(i)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neo_reduced_dataset=reduced_dataset[[\"Activity_Name\"]+real_relevants[:20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "total_arr = np.random.choice(7352, 50, replace=False)\n",
    "train_arr = total_arr[:30]\n",
    "test_arr = total_arr[30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = neo_reduced_dataset.loc[train_arr].reset_index(drop=True)\n",
    "test_dataset = neo_reduced_dataset.loc[test_arr].reset_index(drop=True).drop(columns=\"Activity_Name\")\n",
    "display(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{train_dataset.to_csv()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statement \n",
    "sentence = \"The product quality is amazing but the delivery was delayed. However I am happy with the customer service.\"\n",
    "# System Prompts \n",
    "query = f\"\"\"\n",
    "* You are a Human Activity Recognition model.\n",
    "* Your task is to analyze the data given in the features provided and guess the activity being performed by the person.\n",
    "* The activities are: WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING.\n",
    "* The data features are: {list(train_dataset.columns)[1:]}\n",
    "* Provide a Python list consisting of the activity label for every test sample.\n",
    "\n",
    "Train data: (remember, there are {len(train_dataset)} training samples.)\n",
    "\n",
    "{train_dataset.to_csv()}\n",
    "\n",
    "Now, predict the activity label of the test data: (remember, there are {len(test_dataset)} test samples.)\n",
    "\n",
    "Test data:\n",
    "\n",
    "{test_dataset.to_csv()}\n",
    "\"\"\" \n",
    "\n",
    "#To use Groq LLMs \n",
    "model_name = \"llama3-70b\" # We can choose any model from the groq_models dictionary\n",
    "llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "answer = llm.invoke(query)\n",
    "ans2 = llm.invoke(f\"Extract the python list from this text and output it. Do not say anything else: {answer}\")\n",
    "print(answer.content)\n",
    "print(ans2.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{list(train_dataset.columns)[1:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset.to_csv(sep=\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_arr = []\n",
    "for i in range(len(test_arr)):\n",
    "    correct_arr.append(label(test_arr[i]))\n",
    "    #print(i, label(test_arr[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels= ['WALKING', 'STANDING', 'WALKING', 'WALKING_DOWNSTAIRS', 'STANDING', 'STANDING', 'WALKING_UPSTAIRS', 'STANDING', 'STANDING', 'LAYING', 'WALKING_UPSTAIRS', 'WALKING_DOWNSTAIRS', 'STANDING', 'STANDING', 'WALKING', 'STANDING', 'STANDING', 'LAYING', 'WALKING_UPSTAIRS', 'WALKING_DOWNSTAIRS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.array(predicted_labels)==np.array(correct_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label(135)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from groq import Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Groq(\n",
    "    api_key=Groq_Token,\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"\"\"\n",
    "                * You are a Human Activity Recognition model.\n",
    "                * Your task is to analyze the data given in the features provided and guess the activity being performed by the person.\n",
    "                * The activities are: WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING.\n",
    "                * The features are: {features}\n",
    "                * Provide the activity label and, if necessary, a brief explanation of your reasoning.\n",
    "            \"\"\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"\n",
    "                        Which features do you think are relevant for differentiating between activities?\n",
    "            \"\"\"\n",
    "        }\n",
    "    ],\n",
    "    model=groq_models[\"llama3.1-70b\"],\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Groq(\n",
    "    api_key=Groq_Token,\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"\"\"\n",
    "                * You are a Human Activity Recognition model.\n",
    "                * Your task is to analyze the data given in the features provided and guess the activity being performed by the person.\n",
    "                * The activities are: WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING.\n",
    "                * The features are: {features}\n",
    "                * Provide the activity label and, if necessary, a brief explanation of your reasoning.\n",
    "            \"\"\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"\n",
    "                        Which features do you think are relevant for differentiating between activities?\n",
    "            \"\"\"\n",
    "        }\n",
    "    ],\n",
    "    model=groq_models[\"llama3.1-70b\"],\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"llama3-70b\" # We can choose any model from the groq_models dictionary\n",
    "llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "answer = llm.invoke(f\"Extract the features from the text and output them as a single python array. Do not say anything else.:\\n{chat_completion.choices[0].message.content}\")\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_features = [\n",
    "    \"tBodyAcc-mean()-X\", \"tBodyAcc-mean()-Y\", \"tBodyAcc-mean()-Z\",\n",
    "    \"tBodyAcc-std()-X\", \"tBodyAcc-std()-Y\", \"tBodyAcc-std()-Z\",\n",
    "    \"tBodyAccJerk-mean()-X\", \"tBodyAccJerk-mean()-Y\", \"tBodyAccJerk-mean()-Z\",\n",
    "    \"tBodyGyro-mean()-X\", \"tBodyGyro-mean()-Y\", \"tBodyGyro-mean()-Z\",\n",
    "    \"fBodyAcc-meanFreq()-X\", \"fBodyAcc-meanFreq()-Y\", \"fBodyAcc-meanFreq()-Z\",\n",
    "    \"tBodyAcc-energy()-X\", \"tBodyAcc-energy()-Y\", \"tBodyAcc-energy()-Z\",\n",
    "    \"tBodyAcc-correlation()-X,Y\", \"tBodyAcc-correlation()-X,Z\", \"tBodyAcc-correlation()-Y,Z\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = feature_labels[1].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = feature_labels[1].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_frame=dataframeX.rename(columns=dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_frame = new_frame[relevant_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_frame.insert(0, \"Activity_Name\", act_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(new_frame.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in relevant_features:\n",
    "    if feature not in d:\n",
    "        print(f\"{feature} is not in the features list.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "total_arr = np.random.choice(7352, 50, replace=False)\n",
    "train_arr = total_arr[:40]\n",
    "test_arr = total_arr[40:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roundify(df):\n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].round(2)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = roundify(new_frame.loc[train_arr].reset_index(drop=True))\n",
    "test_dataset = roundify(new_frame.loc[test_arr].reset_index(drop=True).drop(columns=\"Activity_Name\"))\n",
    "display(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statement \n",
    "sentence = \"The product quality is amazing but the delivery was delayed. However I am happy with the customer service.\"\n",
    "# System Prompts \n",
    "query = f\"\"\"\n",
    "* You are a Human Activity Recognition model.\n",
    "* Your task is to analyze the data given in the features provided and guess the activity being performed by the person.\n",
    "* DO NOT use any machine learning models.\n",
    "* The activities are: WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING.\n",
    "* The data features are: {list(train_dataset.columns)[1:]}\n",
    "* Provide a Python list consisting of the activity label for every test sample.\n",
    "\n",
    "Train data: (remember, there are {len(train_dataset)} training samples.)\n",
    "\n",
    "{train_dataset.to_csv(sep=\" \")}\n",
    "\n",
    "Now, predict the activity label of the test data: (remember, there are {len(test_dataset)} test samples.)\n",
    "\n",
    "Test data:\n",
    "{test_dataset.to_csv(sep=\" \")}\n",
    "\"\"\" \n",
    "\n",
    "#To use Groq LLMs \n",
    "model_name = \"llama3-70b\" # We can choose any model from the groq_models dictionary\n",
    "llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "answer = llm.invoke(query)\n",
    "ans2 = llm.invoke(f\"Extract the python list from this text and output it. Do not say anything else: {answer}\")\n",
    "print(answer.content)\n",
    "print(ans2.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = ['LAYING', 'WALKING', 'WALKING_UPSTAIRS', 'LAYING', 'WALKING_DOWNSTAIRS', 'LAYING', 'LAYING', 'SITTING', 'WALKING', 'WALKING_UPSTAIRS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_arr = []\n",
    "for i in range(len(test_arr)):\n",
    "    correct_arr.append(label(test_arr[i]))\n",
    "    #print(i, label(test_arr[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.array(predicted_labels)==np.array(correct_arr)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Groq(\n",
    "    api_key=Groq_Token,\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"\"\"\n",
    "                * You are a Human Activity Recognition model.\n",
    "                * Your task is to analyze the data given in the features provided and guess the activity being performed by the person.\n",
    "                * The activities are: WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING.\n",
    "                * The features are: {features}\n",
    "                * Provide the activity label and, if necessary, a brief explanation of your reasoning.\n",
    "            \"\"\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"\n",
    "                        Which features do you think are relevant for differentiating between activities?\n",
    "            \"\"\"\n",
    "        }\n",
    "    ],\n",
    "    model=groq_models[\"llama3.1-70b\"],\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Groq(\n",
    "    api_key=Groq_Token,\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"\"\"\n",
    "                * You are a Human Activity Recognition model.\n",
    "                * Your task is to analyze the data given in the features provided and guess the activity being performed by the person.\n",
    "                * The activities are: WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING.\n",
    "                * The features are: {features}\n",
    "                * Provide the activity label and, if necessary, a brief explanation of your reasoning.\n",
    "            \"\"\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"\n",
    "                        Which features do you think are relevant for differentiating between activities? Provide the output as a single copyable python array.\n",
    "            \"\"\"\n",
    "        }\n",
    "    ],\n",
    "    model=groq_models[\"llama3.1-70b\"],\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Groq(\n",
    "    api_key=Groq_Token,\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"\"\"\n",
    "                * You are a Human Activity Recognition model.\n",
    "                * Your task is to analyze the data given in the features provided and guess the activity being performed by the person.\n",
    "                * The activities are: WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING.\n",
    "                * The features are: {features}\n",
    "                * Provide the activity label and, if necessary, a brief explanation of your reasoning.\n",
    "            \"\"\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"\n",
    "                        Look at these examples for reference:\n",
    "                        Example 1: \n",
    "                        \n",
    "                        Feature Data: {\" \".join(map(str, example()))}\n",
    "                        Activity Label: {label(489)}\n",
    "\n",
    "                        Example 2:\n",
    "                        Feature Data: {\" \".join(map(str, example(100)))}\n",
    "                        Activity Label: {label(100)}\n",
    "\n",
    "                        Example 3:\n",
    "                        Feature Data: {\" \".join(map(str, example(345)))}\n",
    "                        Activity Label: {label(345)}\n",
    "                        \n",
    "                        Now, predict this:\n",
    "                        Feature Data: {\" \".join(map(str, example(706)))}\n",
    "            \"\"\"\n",
    "        }\n",
    "    ],\n",
    "    #model=groq_models[\"llama3-70b\"],\n",
    "    model = \"llama-3.1-70b-versatile\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_dic = {\"WALKING\":[], \"WALKING_UPSTAIRS\": [], \"WALKING_DOWNSTAIRS\": [], \"SITTING\": [], \"STANDING\": [], \"LAYING\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dataframeY[0].to_numpy())):\n",
    "    act_dic[label(i)].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['WALKING', 'WALKING_UPSTAIRS', 'WALKING_DOWNSTAIRS', 'SITTING', 'STANDING', 'LAYING'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_dic.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "                * You are a Human Activity Recognition model.\n",
    "                * Your task is to analyze the data given in the features provided and guess the activity being performed by the person.\n",
    "                * The activities are: WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING.\n",
    "                * The training dataset is: {train_dataset}\n",
    "                * Provide the activity label and, if necessary, a brief explanation of your reasoning.\n",
    "            \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statement \n",
    "sentence = \"The product quality is amazing but the delivery was delayed. However I am happy with the customer service.\"\n",
    "# System Prompts \n",
    "query = f\"\"\"\n",
    "* You are a Human Activity Recognition model.\n",
    "* Your task is to analyze the data given in the features provided and guess the activity being performed by the person.\n",
    "* DO NOT use any machine learning models.\n",
    "* The activities are: WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING.\n",
    "* The data features are: {list(train_dataset.columns)[1:]}\n",
    "* Provide a Python list consisting of the activity label for every test sample.\n",
    "\n",
    "Here is the training data:\n",
    "Activity label: WALKING:\n",
    "{training_frames[0]} \n",
    "\n",
    "\n",
    "\n",
    "Now, predict the activity label of the test data: (remember, there are {len(test_dataset)} test samples.)\n",
    "\n",
    "Test data:\n",
    "{test_dataset.to_csv(sep=\" \")}\n",
    "\"\"\" \n",
    "\n",
    "#To use Groq LLMs \n",
    "model_name = \"llama3-70b\" # We can choose any model from the groq_models dictionary\n",
    "llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "answer = llm.invoke(query)\n",
    "ans2 = llm.invoke(f\"Extract the python list from this text and output it. Do not say anything else: {answer}\")\n",
    "print(answer.content)\n",
    "print(ans2.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_frames = [new_frame[new_frame[\"Activity_Name\"]==i].sample(n=2, random_state=42).reset_index(drop=True) for i in act_dic.keys()]\n",
    "#walking_frame_train = walking_frame.loc[:10].reset_index(drop=True)\n",
    "#display(walking_frame_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity_Name</th>\n",
       "      <th>tBodyAcc-mean()-X</th>\n",
       "      <th>tBodyAcc-mean()-Y</th>\n",
       "      <th>tBodyAcc-mean()-Z</th>\n",
       "      <th>tBodyAcc-std()-X</th>\n",
       "      <th>tBodyAcc-std()-Y</th>\n",
       "      <th>tBodyAcc-std()-Z</th>\n",
       "      <th>tBodyAccJerk-mean()-X</th>\n",
       "      <th>tBodyAccJerk-mean()-Y</th>\n",
       "      <th>tBodyAccJerk-mean()-Z</th>\n",
       "      <th>...</th>\n",
       "      <th>tBodyGyro-mean()-Z</th>\n",
       "      <th>fBodyAcc-meanFreq()-X</th>\n",
       "      <th>fBodyAcc-meanFreq()-Y</th>\n",
       "      <th>fBodyAcc-meanFreq()-Z</th>\n",
       "      <th>tBodyAcc-energy()-X</th>\n",
       "      <th>tBodyAcc-energy()-Y</th>\n",
       "      <th>tBodyAcc-energy()-Z</th>\n",
       "      <th>tBodyAcc-correlation()-X,Y</th>\n",
       "      <th>tBodyAcc-correlation()-X,Z</th>\n",
       "      <th>tBodyAcc-correlation()-Y,Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>STANDING</td>\n",
       "      <td>0.288585</td>\n",
       "      <td>-0.020294</td>\n",
       "      <td>-0.132905</td>\n",
       "      <td>-0.995279</td>\n",
       "      <td>-0.983111</td>\n",
       "      <td>-0.913526</td>\n",
       "      <td>0.077996</td>\n",
       "      <td>0.005001</td>\n",
       "      <td>-0.067831</td>\n",
       "      <td>...</td>\n",
       "      <td>0.107725</td>\n",
       "      <td>0.252483</td>\n",
       "      <td>0.131836</td>\n",
       "      <td>-0.052050</td>\n",
       "      <td>-0.999945</td>\n",
       "      <td>-0.999863</td>\n",
       "      <td>-0.994612</td>\n",
       "      <td>0.376314</td>\n",
       "      <td>0.435129</td>\n",
       "      <td>0.660790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>STANDING</td>\n",
       "      <td>0.278419</td>\n",
       "      <td>-0.016411</td>\n",
       "      <td>-0.123520</td>\n",
       "      <td>-0.998245</td>\n",
       "      <td>-0.975300</td>\n",
       "      <td>-0.960322</td>\n",
       "      <td>0.074007</td>\n",
       "      <td>0.005771</td>\n",
       "      <td>0.029377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100584</td>\n",
       "      <td>0.271309</td>\n",
       "      <td>0.042864</td>\n",
       "      <td>-0.014310</td>\n",
       "      <td>-0.999991</td>\n",
       "      <td>-0.999788</td>\n",
       "      <td>-0.998405</td>\n",
       "      <td>-0.013429</td>\n",
       "      <td>-0.072692</td>\n",
       "      <td>0.579382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>STANDING</td>\n",
       "      <td>0.279653</td>\n",
       "      <td>-0.019467</td>\n",
       "      <td>-0.113462</td>\n",
       "      <td>-0.995380</td>\n",
       "      <td>-0.967187</td>\n",
       "      <td>-0.978944</td>\n",
       "      <td>0.073636</td>\n",
       "      <td>0.003104</td>\n",
       "      <td>-0.009046</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096127</td>\n",
       "      <td>0.124531</td>\n",
       "      <td>-0.064611</td>\n",
       "      <td>0.082677</td>\n",
       "      <td>-0.999969</td>\n",
       "      <td>-0.999660</td>\n",
       "      <td>-0.999470</td>\n",
       "      <td>-0.124698</td>\n",
       "      <td>-0.181105</td>\n",
       "      <td>0.608900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>STANDING</td>\n",
       "      <td>0.279174</td>\n",
       "      <td>-0.026201</td>\n",
       "      <td>-0.123283</td>\n",
       "      <td>-0.996091</td>\n",
       "      <td>-0.983403</td>\n",
       "      <td>-0.990675</td>\n",
       "      <td>0.077321</td>\n",
       "      <td>0.020058</td>\n",
       "      <td>-0.009865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085538</td>\n",
       "      <td>0.029044</td>\n",
       "      <td>0.080302</td>\n",
       "      <td>0.185695</td>\n",
       "      <td>-0.999976</td>\n",
       "      <td>-0.999736</td>\n",
       "      <td>-0.999504</td>\n",
       "      <td>-0.305693</td>\n",
       "      <td>-0.362654</td>\n",
       "      <td>0.507459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>STANDING</td>\n",
       "      <td>0.276629</td>\n",
       "      <td>-0.016570</td>\n",
       "      <td>-0.115362</td>\n",
       "      <td>-0.998139</td>\n",
       "      <td>-0.980817</td>\n",
       "      <td>-0.990482</td>\n",
       "      <td>0.073444</td>\n",
       "      <td>0.019122</td>\n",
       "      <td>0.016780</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077392</td>\n",
       "      <td>0.181090</td>\n",
       "      <td>0.057988</td>\n",
       "      <td>0.559786</td>\n",
       "      <td>-0.999991</td>\n",
       "      <td>-0.999856</td>\n",
       "      <td>-0.999757</td>\n",
       "      <td>-0.155804</td>\n",
       "      <td>-0.189763</td>\n",
       "      <td>0.599213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Activity_Name  tBodyAcc-mean()-X  tBodyAcc-mean()-Y  tBodyAcc-mean()-Z  \\\n",
       "0      STANDING           0.288585          -0.020294          -0.132905   \n",
       "1      STANDING           0.278419          -0.016411          -0.123520   \n",
       "2      STANDING           0.279653          -0.019467          -0.113462   \n",
       "3      STANDING           0.279174          -0.026201          -0.123283   \n",
       "4      STANDING           0.276629          -0.016570          -0.115362   \n",
       "\n",
       "   tBodyAcc-std()-X  tBodyAcc-std()-Y  tBodyAcc-std()-Z  \\\n",
       "0         -0.995279         -0.983111         -0.913526   \n",
       "1         -0.998245         -0.975300         -0.960322   \n",
       "2         -0.995380         -0.967187         -0.978944   \n",
       "3         -0.996091         -0.983403         -0.990675   \n",
       "4         -0.998139         -0.980817         -0.990482   \n",
       "\n",
       "   tBodyAccJerk-mean()-X  tBodyAccJerk-mean()-Y  tBodyAccJerk-mean()-Z  ...  \\\n",
       "0               0.077996               0.005001              -0.067831  ...   \n",
       "1               0.074007               0.005771               0.029377  ...   \n",
       "2               0.073636               0.003104              -0.009046  ...   \n",
       "3               0.077321               0.020058              -0.009865  ...   \n",
       "4               0.073444               0.019122               0.016780  ...   \n",
       "\n",
       "   tBodyGyro-mean()-Z  fBodyAcc-meanFreq()-X  fBodyAcc-meanFreq()-Y  \\\n",
       "0            0.107725               0.252483               0.131836   \n",
       "1            0.100584               0.271309               0.042864   \n",
       "2            0.096127               0.124531              -0.064611   \n",
       "3            0.085538               0.029044               0.080302   \n",
       "4            0.077392               0.181090               0.057988   \n",
       "\n",
       "   fBodyAcc-meanFreq()-Z  tBodyAcc-energy()-X  tBodyAcc-energy()-Y  \\\n",
       "0              -0.052050            -0.999945            -0.999863   \n",
       "1              -0.014310            -0.999991            -0.999788   \n",
       "2               0.082677            -0.999969            -0.999660   \n",
       "3               0.185695            -0.999976            -0.999736   \n",
       "4               0.559786            -0.999991            -0.999856   \n",
       "\n",
       "   tBodyAcc-energy()-Z  tBodyAcc-correlation()-X,Y  \\\n",
       "0            -0.994612                    0.376314   \n",
       "1            -0.998405                   -0.013429   \n",
       "2            -0.999470                   -0.124698   \n",
       "3            -0.999504                   -0.305693   \n",
       "4            -0.999757                   -0.155804   \n",
       "\n",
       "   tBodyAcc-correlation()-X,Z  tBodyAcc-correlation()-Y,Z  \n",
       "0                    0.435129                    0.660790  \n",
       "1                   -0.072692                    0.579382  \n",
       "2                   -0.181105                    0.608900  \n",
       "3                   -0.362654                    0.507459  \n",
       "4                   -0.189763                    0.599213  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(new_frame.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['WALKING', 'WALKING_UPSTAIRS', 'WALKING_DOWNSTAIRS', 'SITTING', 'STANDING', 'LAYING'])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_dic.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_frames = [frame.loc[:1].reset_index(drop=True) for frame in all_frames]\n",
    "test_frames = [frame.loc[1:].reset_index(drop=True) for frame in all_frames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity_Name</th>\n",
       "      <th>tBodyAcc-mean()-X</th>\n",
       "      <th>tBodyAcc-mean()-Y</th>\n",
       "      <th>tBodyAcc-mean()-Z</th>\n",
       "      <th>tBodyAcc-std()-X</th>\n",
       "      <th>tBodyAcc-std()-Y</th>\n",
       "      <th>tBodyAcc-std()-Z</th>\n",
       "      <th>tBodyAccJerk-mean()-X</th>\n",
       "      <th>tBodyAccJerk-mean()-Y</th>\n",
       "      <th>tBodyAccJerk-mean()-Z</th>\n",
       "      <th>...</th>\n",
       "      <th>tBodyGyro-mean()-Z</th>\n",
       "      <th>fBodyAcc-meanFreq()-X</th>\n",
       "      <th>fBodyAcc-meanFreq()-Y</th>\n",
       "      <th>fBodyAcc-meanFreq()-Z</th>\n",
       "      <th>tBodyAcc-energy()-X</th>\n",
       "      <th>tBodyAcc-energy()-Y</th>\n",
       "      <th>tBodyAcc-energy()-Z</th>\n",
       "      <th>tBodyAcc-correlation()-X,Y</th>\n",
       "      <th>tBodyAcc-correlation()-X,Z</th>\n",
       "      <th>tBodyAcc-correlation()-Y,Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WALKING_UPSTAIRS</td>\n",
       "      <td>0.29</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>-0.38</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0.32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.85</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>-0.85</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>-0.79</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>-0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SITTING</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>-0.96</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>-0.85</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0.07</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>0.12</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-0.96</td>\n",
       "      <td>-0.98</td>\n",
       "      <td>0.38</td>\n",
       "      <td>-0.73</td>\n",
       "      <td>-0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>STANDING</td>\n",
       "      <td>0.28</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.43</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LAYING</td>\n",
       "      <td>0.23</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-0.94</td>\n",
       "      <td>-0.91</td>\n",
       "      <td>-0.98</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.38</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>0.38</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>-0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WALKING</td>\n",
       "      <td>0.21</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>0.40</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.34</td>\n",
       "      <td>...</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-0.77</td>\n",
       "      <td>-0.82</td>\n",
       "      <td>-0.74</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WALKING_DOWNSTAIRS</td>\n",
       "      <td>0.36</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>0.40</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>0.19</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.85</td>\n",
       "      <td>-0.56</td>\n",
       "      <td>0.24</td>\n",
       "      <td>-0.65</td>\n",
       "      <td>-0.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Activity_Name  tBodyAcc-mean()-X  tBodyAcc-mean()-Y  \\\n",
       "0    WALKING_UPSTAIRS               0.29              -0.01   \n",
       "1             SITTING               0.32               0.02   \n",
       "2            STANDING               0.28              -0.01   \n",
       "3              LAYING               0.23              -0.02   \n",
       "4             WALKING               0.21              -0.04   \n",
       "5  WALKING_DOWNSTAIRS               0.36              -0.02   \n",
       "\n",
       "   tBodyAcc-mean()-Z  tBodyAcc-std()-X  tBodyAcc-std()-Y  tBodyAcc-std()-Z  \\\n",
       "0              -0.19             -0.46             -0.38             -0.34   \n",
       "1              -0.18             -0.96             -0.59             -0.85   \n",
       "2              -0.10             -1.00             -0.99             -0.99   \n",
       "3              -0.11             -0.94             -0.91             -0.98   \n",
       "4              -0.10             -0.32             -0.03             -0.24   \n",
       "5              -0.14              0.40             -0.12             -0.01   \n",
       "\n",
       "   tBodyAccJerk-mean()-X  tBodyAccJerk-mean()-Y  tBodyAccJerk-mean()-Z  ...  \\\n",
       "0                   0.05                  -0.07                   0.32  ...   \n",
       "1                   0.05                  -0.20                   0.07  ...   \n",
       "2                   0.07                   0.01                   0.00  ...   \n",
       "3                   0.12                   0.04                   0.00  ...   \n",
       "4                   0.40                  -0.08                   0.34  ...   \n",
       "5                  -0.15                  -0.28                   0.19  ...   \n",
       "\n",
       "   tBodyGyro-mean()-Z  fBodyAcc-meanFreq()-X  fBodyAcc-meanFreq()-Y  \\\n",
       "0                0.07                  -0.85                  -0.52   \n",
       "1               -0.29                   0.12                  -0.10   \n",
       "2                0.09                   0.07                   0.22   \n",
       "3                0.11                  -0.38                  -0.30   \n",
       "4                0.13                  -0.07                  -0.12   \n",
       "5                0.01                  -0.51                   0.07   \n",
       "\n",
       "   fBodyAcc-meanFreq()-Z  tBodyAcc-energy()-X  tBodyAcc-energy()-Y  \\\n",
       "0                  -0.27                -0.85                -0.92   \n",
       "1                  -0.20                -1.00                -0.96   \n",
       "2                   0.43                -1.00                -1.00   \n",
       "3                   0.38                -1.00                -1.00   \n",
       "4                   0.39                -0.77                -0.82   \n",
       "5                   0.01                -0.02                -0.85   \n",
       "\n",
       "   tBodyAcc-energy()-Z  tBodyAcc-correlation()-X,Y  \\\n",
       "0                -0.79                       -0.07   \n",
       "1                -0.98                        0.38   \n",
       "2                -1.00                        0.01   \n",
       "3                -1.00                        0.60   \n",
       "4                -0.74                       -0.39   \n",
       "5                -0.56                        0.24   \n",
       "\n",
       "   tBodyAcc-correlation()-X,Z  tBodyAcc-correlation()-Y,Z  \n",
       "0                       -0.45                       -0.31  \n",
       "1                       -0.73                       -0.74  \n",
       "2                       -0.14                        0.27  \n",
       "3                       -0.14                       -0.33  \n",
       "4                       -0.23                        0.49  \n",
       "5                       -0.65                       -0.28  \n",
       "\n",
       "[6 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_frame_data = pd.concat(test_frames).reset_index(drop=True)\n",
    "# Shuffle test_frame_data and remove the activity labels\n",
    "test_frame_data = roundify(test_frame_data.sample(frac=1, random_state=13).reset_index(drop=True))\n",
    "test_data = test_frame_data.drop(columns=\"Activity_Name\")\n",
    "#test_frame_data = test_frame_data.drop(columns=\"Activity_Name\")\n",
    "display(test_frame_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['WALKING_DOWNSTAIRS', 'LAYING', 'WALKING_DOWNSTAIRS', 'LAYING', 'STANDING', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'LAYING', 'LAYING', 'WALKING', 'WALKING', 'WALKING_UPSTAIRS']\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "# Statement \n",
    "sentence = \"The product quality is amazing but the delivery was delayed. However I am happy with the customer service.\"\n",
    "# System Prompts \n",
    "query = f\"\"\"\n",
    "* You are a Human Activity Recognition model.\n",
    "* Your task is to analyze the data given in the features provided and guess the activity being performed by the person.\n",
    "* DO NOT use any machine learning models.\n",
    "* The activities are: WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING.\n",
    "* Provide a Python list consisting of the activity label for every test sample.\n",
    "\n",
    "Here is the training data:\n",
    "Activity label: WALKING:\n",
    "{roundify(training_frames[0]).to_csv(sep=\" \")}\n",
    "\n",
    "Activity label: WALKING_UPSTAIRS:\n",
    "{roundify(training_frames[1]).to_csv(sep=\" \")}\n",
    "\n",
    "Activity label: WALKING_DOWNSTAIRS:\n",
    "{roundify(training_frames[2]).to_csv(sep=\" \")}\n",
    "\n",
    "Activity label: SITTING:\n",
    "{roundify(training_frames[3]).to_csv(sep=\" \")}\n",
    "\n",
    "Activity label: STANDING:\n",
    "{roundify(training_frames[4]).to_csv(sep=\" \")}\n",
    "\n",
    "Activity label: LAYING:\n",
    "{roundify(training_frames[5]).to_csv(sep=\" \")}\n",
    "\n",
    "\n",
    "Now, predict the activity label of the test data: (remember, there are {len(test_frame_data)} test samples.)\n",
    "DO NOT output the python code. Just provide your predictions as a python list.\n",
    "Test data:\n",
    "{test_data.to_csv(sep=\" \")}\n",
    "\"\"\" \n",
    "\n",
    "#To use Groq LLMs \n",
    "model_name = \"llama3.1-70b\" # We can choose any model from the groq_models dictionary\n",
    "llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "answer = llm.invoke(query)\n",
    "#ans2 = llm.invoke(f\"Extract the python list from this text and output it. Do not say anything else: {answer}\")\n",
    "print(answer.content)\n",
    "predicted_labels = ast.literal_eval(answer.content)\n",
    "actual_labels = test_frame_data[\"Activity_Name\"].to_list()\n",
    "print((np.array(actual_labels)==np.array(predicted_labels)).mean())\n",
    "#print(ans2.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = ['LAYING', 'LAYING', 'WALKING', 'STANDING', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'WALKING_DOWNSTAIRS', 'LAYING', 'LAYING', 'LAYING', 'LAYING', 'LAYING']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "* The data features are: {list(train_dataset.columns)[1:]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(actual_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4166666666666667"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array(actual_labels)==np.array(predicted_labels)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statement \n",
    "def predict(testdf):\n",
    "    # System Prompts \n",
    "    query = f\"\"\"\n",
    "    * You are a Human Activity Recognition model.\n",
    "    * Your task is to analyze the data given in the features provided and guess the activity being performed by the person.\n",
    "    * DO NOT use any machine learning models.\n",
    "    * The activities are: WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING.\n",
    "    * Provide a Python list consisting of the activity label for every test sample.\n",
    "\n",
    "    Here is the training data:\n",
    "    Activity label: WALKING:\n",
    "    {roundify(training_frames[0]).to_csv(sep=\" \")}\n",
    "\n",
    "    Activity label: WALKING_UPSTAIRS:\n",
    "    {roundify(training_frames[1]).to_csv(sep=\" \")}\n",
    "\n",
    "    Activity label: WALKING_DOWNSTAIRS:\n",
    "    {roundify(training_frames[2]).to_csv(sep=\" \")}\n",
    "\n",
    "    Activity label: SITTING:\n",
    "    {roundify(training_frames[3]).to_csv(sep=\" \")}\n",
    "\n",
    "    Activity label: STANDING:\n",
    "    {roundify(training_frames[4]).to_csv(sep=\" \")}\n",
    "\n",
    "    Activity label: LAYING:\n",
    "    {roundify(training_frames[5]).to_csv(sep=\" \")}\n",
    "\n",
    "\n",
    "    Now, predict the activity label of the test data: (remember, there are {len(testdf)} test samples.)\n",
    "    DO NOT output the python code. Just provide your predictions as a python list.\n",
    "    Test data:\n",
    "    {testdf.to_csv(sep=\" \")}\n",
    "    \"\"\" \n",
    "\n",
    "    #To use Groq LLMs \n",
    "    model_name = \"llama3.1-70b\" # We can choose any model from the groq_models dictionary\n",
    "    llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "    answer = llm.invoke(query)\n",
    "    #ans2 = llm.invoke(f\"Extract the python list from this text and output it. Do not say anything else: {answer}\")\n",
    "    #print(answer.content)\n",
    "    predicted_labels = ast.literal_eval(answer.content)\n",
    "    time.sleep(1)\n",
    "    return predicted_labels\n",
    "    #print((np.array(actual_labels)==np.array(predicted_labels)).mean())\n",
    "    #print(ans2.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accarr = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8333333333333334,\n",
       " 0.8333333333333334,\n",
       " 0.75,\n",
       " 0.8333333333333334,\n",
       " 0.6666666666666666,\n",
       " 0.3333333333333333,\n",
       " 0.5833333333333334,\n",
       " 0.5833333333333334,\n",
       " 0.4166666666666667]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Prediction 0: WALKING\n",
      "Prediction 1: WALKING\n",
      "Prediction 2: WALKING_UPSTAIRS\n",
      "Prediction 3: WALKING\n",
      "Prediction 4: WALKING_DOWNSTAIRS\n",
      "Prediction 5: WALKING_DOWNSTAIRS\n",
      "Prediction 6: SITTING\n",
      "Prediction 7: STANDING\n",
      "Prediction 8: STANDING\n",
      "Prediction 9: STANDING\n",
      "Prediction 10: LAYING\n",
      "Prediction 11: LAYING\n",
      "0.8333333333333334\n",
      "====================\n",
      "2\n",
      "Prediction 0: WALKING\n",
      "Prediction 1: WALKING\n",
      "Prediction 2: WALKING_UPSTAIRS\n",
      "Prediction 3: WALKING_UPSTAIRS\n",
      "Prediction 4: WALKING_DOWNSTAIRS\n",
      "Prediction 5: WALKING_DOWNSTAIRS\n",
      "Prediction 6: SITTING\n",
      "Prediction 7: STANDING\n",
      "Prediction 8: STANDING\n",
      "Prediction 9: STANDING\n",
      "Prediction 10: LAYING\n",
      "Prediction 11: WALKING\n",
      "0.8333333333333334\n",
      "====================\n",
      "3\n",
      "Prediction 0: WALKING\n",
      "Prediction 1: WALKING\n",
      "Prediction 2: WALKING_DOWNSTAIRS\n",
      "Prediction 3: WALKING\n",
      "Prediction 4: WALKING_DOWNSTAIRS\n",
      "Prediction 5: WALKING_DOWNSTAIRS\n",
      "Prediction 6: SITTING\n",
      "Prediction 7: SITTING\n",
      "Prediction 8: STANDING\n",
      "Prediction 9: STANDING\n",
      "Prediction 10: LAYING\n",
      "Prediction 11: SITTING\n",
      "0.75\n",
      "====================\n",
      "4\n",
      "Prediction 0: WALKING\n",
      "Prediction 1: WALKING\n",
      "Prediction 2: WALKING_UPSTAIRS\n",
      "Prediction 3: WALKING_UPSTAIRS\n",
      "Prediction 4: WALKING_DOWNSTAIRS\n",
      "Prediction 5: WALKING_UPSTAIRS\n",
      "Prediction 6: SITTING\n",
      "Prediction 7: SITTING\n",
      "Prediction 8: STANDING\n",
      "Prediction 9: STANDING\n",
      "Prediction 10: LAYING\n",
      "Prediction 11: STANDING\n",
      "0.8333333333333334\n",
      "====================\n",
      "5\n",
      "Prediction 0: WALKING\n",
      "Prediction 1: WALKING\n",
      "Prediction 2: WALKING_UPSTAIRS\n",
      "Prediction 3: WALKING_DOWNSTAIRS\n",
      "Prediction 4: WALKING_DOWNSTAIRS\n",
      "Prediction 5: WALKING\n",
      "Prediction 6: SITTING\n",
      "Prediction 7: WALKING_UPSTAIRS\n",
      "Prediction 8: STANDING\n",
      "Prediction 9: STANDING\n",
      "Prediction 10: LAYING\n",
      "Prediction 11: WALKING\n",
      "0.6666666666666666\n",
      "====================\n",
      "6\n",
      "Prediction 0: WALKING\n",
      "Prediction 1: WALKING\n",
      "Prediction 2: WALKING\n",
      "Prediction 3: WALKING\n",
      "Prediction 4: WALKING\n",
      "Prediction 5: WALKING_UPSTAIRS\n",
      "Prediction 6: WALKING\n",
      "Prediction 7: SITTING\n",
      "Prediction 8: SITTING\n",
      "Prediction 9: SITTING\n",
      "Prediction 10: LAYING\n",
      "Prediction 11: SITTING\n",
      "0.3333333333333333\n",
      "====================\n",
      "7\n",
      "Prediction 0: WALKING\n",
      "Prediction 1: WALKING\n",
      "Prediction 2: WALKING\n",
      "Prediction 3: WALKING_UPSTAIRS\n",
      "Prediction 4: LAYING\n",
      "Prediction 5: WALKING\n",
      "Prediction 6: SITTING\n",
      "Prediction 7: SITTING\n",
      "Prediction 8: STANDING\n",
      "Prediction 9: SITTING\n",
      "Prediction 10: LAYING\n",
      "Prediction 11: SITTING\n",
      "0.5833333333333334\n",
      "====================\n",
      "8\n",
      "Prediction 0: WALKING\n",
      "Prediction 1: WALKING\n",
      "Prediction 2: WALKING_DOWNSTAIRS\n",
      "Prediction 3: WALKING\n",
      "Prediction 4: WALKING_DOWNSTAIRS\n",
      "Prediction 5: WALKING_DOWNSTAIRS\n",
      "Prediction 6: LAYING\n",
      "Prediction 7: SITTING\n",
      "Prediction 8: WALKING\n",
      "Prediction 9: WALKING\n",
      "Prediction 10: LAYING\n",
      "Prediction 11: LAYING\n",
      "0.5833333333333334\n",
      "====================\n",
      "9\n",
      "Prediction 0: WALKING\n",
      "Prediction 1: WALKING_DOWNSTAIRS\n",
      "Prediction 2: WALKING\n",
      "Prediction 3: WALKING_DOWNSTAIRS\n",
      "Prediction 4: WALKING_DOWNSTAIRS\n",
      "Prediction 5: WALKING_UPSTAIRS\n",
      "Prediction 6: WALKING\n",
      "Prediction 7: LAYING\n",
      "Prediction 8: WALKING\n",
      "Prediction 9: STANDING\n",
      "Prediction 10: LAYING\n",
      "Prediction 11: LAYING\n",
      "0.4166666666666667\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "#accarr = []\n",
    "for i in range(10, 20):\n",
    "    print(i)\n",
    "    predictions = []\n",
    "    all_frames = [new_frame[new_frame[\"Activity_Name\"]==act].sample(n=i+2, random_state=42).reset_index(drop=True) for act in act_dic.keys()]\n",
    "    training_frames = [frame.loc[:i].reset_index(drop=True) for frame in all_frames]\n",
    "    test_frames = [frame.loc[i:].reset_index(drop=True) for frame in all_frames]\n",
    "    test_frame_data = pd.concat(test_frames).reset_index(drop=True)\n",
    "    test_data = test_frame_data.drop(columns=\"Activity_Name\")\n",
    "    actual_labels = test_frame_data[\"Activity_Name\"].to_list()\n",
    "    for j in range(len(test_data)):\n",
    "        prediction = predict(test_data.loc[[j]])[0]\n",
    "        print(f\"Prediction {j}: {prediction}\")\n",
    "        predictions.append(prediction)\n",
    "    accuracy = (np.array(actual_labels)==np.array(predictions)).mean()\n",
    "    print(accuracy)\n",
    "    print(\"====================\")\n",
    "    accarr.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Prediction 0: WALKING\n",
      "Prediction 1: WALKING\n",
      "Prediction 2: WALKING_UPSTAIRS\n",
      "Prediction 3: WALKING\n",
      "Prediction 4: WALKING_DOWNSTAIRS\n",
      "Prediction 5: WALKING_UPSTAIRS\n",
      "Prediction 6: SITTING\n",
      "Prediction 7: SITTING\n",
      "Prediction 8: WALKING\n",
      "Prediction 9: LAYING\n",
      "Prediction 10: WALKING\n",
      "Prediction 11: STANDING\n",
      "0.5\n",
      "====================\n",
      "11\n",
      "Prediction 0: WALKING\n",
      "Prediction 1: WALKING_DOWNSTAIRS\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-70b-versatile` in organization `org_01j57vym4qfngrwhcawhdpybvr` on : Limit 1000000, Used 1000336, Requested 3404. Please try again in 5m23.1508s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': '', 'code': 'rate_limit_exceeded'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[234], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m actual_labels \u001b[38;5;241m=\u001b[39m test_frame_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mActivity_Name\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto_list()\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(test_data)):\n\u001b[1;32m---> 12\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrediction \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprediction\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m     predictions\u001b[38;5;241m.\u001b[39mappend(prediction)\n",
      "Cell \u001b[1;32mIn[229], line 40\u001b[0m, in \u001b[0;36mpredict\u001b[1;34m(testdf)\u001b[0m\n\u001b[0;32m     38\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllama3.1-70b\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;66;03m# We can choose any model from the groq_models dictionary\u001b[39;00m\n\u001b[0;32m     39\u001b[0m llm \u001b[38;5;241m=\u001b[39m ChatGroq(model\u001b[38;5;241m=\u001b[39mgroq_models[model_name], api_key\u001b[38;5;241m=\u001b[39mGroq_Token, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 40\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m#ans2 = llm.invoke(f\"Extract the python list from this text and output it. Do not say anything else: {answer}\")\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m#print(answer.content)\u001b[39;00m\n\u001b[0;32m     43\u001b[0m predicted_labels \u001b[38;5;241m=\u001b[39m ast\u001b[38;5;241m.\u001b[39mliteral_eval(answer\u001b[38;5;241m.\u001b[39mcontent)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:276\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    267\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    272\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m    273\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    275\u001b[0m         ChatGeneration,\n\u001b[1;32m--> 276\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    286\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:776\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    769\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    770\u001b[0m     prompts: List[PromptValue],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    773\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    774\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    775\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 776\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:633\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    631\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[0;32m    632\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[1;32m--> 633\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    634\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    635\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[0;32m    636\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[0;32m    637\u001b[0m ]\n\u001b[0;32m    638\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:623\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    620\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[0;32m    621\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    622\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 623\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    624\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    625\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    626\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    627\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    629\u001b[0m         )\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    631\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:845\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    843\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    844\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 845\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    848\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    849\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\langchain_groq\\chat_models.py:472\u001b[0m, in \u001b[0;36mChatGroq._generate\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    467\u001b[0m message_dicts, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_message_dicts(messages, stop)\n\u001b[0;32m    468\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    469\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    470\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    471\u001b[0m }\n\u001b[1;32m--> 472\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\groq\\resources\\chat\\completions.py:289\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    177\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    178\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m    179\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;124;03m    Creates a model response for the given chat conversation.\u001b[39;00m\n\u001b[0;32m    181\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;124;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/openai/v1/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    303\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    304\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    305\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    306\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    307\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    308\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    309\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\groq\\_base_client.py:1225\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1211\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1212\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1213\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1220\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1221\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1222\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1223\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1224\u001b[0m     )\n\u001b[1;32m-> 1225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\groq\\_base_client.py:920\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    911\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    912\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    913\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    918\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    919\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m--> 920\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\groq\\_base_client.py:1018\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1015\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1017\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1018\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1020\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1021\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1022\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1025\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1026\u001b[0m )\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-70b-versatile` in organization `org_01j57vym4qfngrwhcawhdpybvr` on : Limit 1000000, Used 1000336, Requested 3404. Please try again in 5m23.1508s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': '', 'code': 'rate_limit_exceeded'}}"
     ]
    }
   ],
   "source": [
    "#accarr = []\n",
    "for i in range(10, 20):\n",
    "    print(i)\n",
    "    predictions = []\n",
    "    all_frames = [new_frame[new_frame[\"Activity_Name\"]==act].sample(n=i+2, random_state=42).reset_index(drop=True) for act in act_dic.keys()]\n",
    "    training_frames = [frame.loc[:i].reset_index(drop=True) for frame in all_frames]\n",
    "    test_frames = [frame.loc[i:].reset_index(drop=True) for frame in all_frames]\n",
    "    test_frame_data = pd.concat(test_frames).reset_index(drop=True)\n",
    "    test_data = test_frame_data.drop(columns=\"Activity_Name\")\n",
    "    actual_labels = test_frame_data[\"Activity_Name\"].to_list()\n",
    "    for j in range(len(test_data)):\n",
    "        prediction = predict(test_data.loc[[j]])[0]\n",
    "        print(f\"Prediction {j}: {prediction}\")\n",
    "        predictions.append(prediction)\n",
    "    accuracy = (np.array(actual_labels)==np.array(predictions)).mean()\n",
    "    print(accuracy)\n",
    "    print(\"====================\")\n",
    "    accarr.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['WALKING_UPSTAIRS']\n",
      "['SITTING']\n",
      "['STANDING']\n",
      "['LAYING']\n",
      "['WALKING']\n",
      "['WALKING_DOWNSTAIRS']\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(test_data)):\n",
    "    predictions.append((predict(test_data.loc[[i]]))[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8333333333333334,\n",
       " 0.8333333333333334,\n",
       " 0.75,\n",
       " 0.8333333333333334,\n",
       " 0.6666666666666666,\n",
       " 0.3333333333333333,\n",
       " 0.5833333333333334,\n",
       " 0.5833333333333334,\n",
       " 0.4166666666666667,\n",
       " 0.5]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2d3f7ff5ac0>]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(accarr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['WALKING']\n"
     ]
    }
   ],
   "source": [
    "a = predict(test_data.loc[[10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_labels = test_frame_data[\"Activity_Name\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array(predictions)==np.array(actual_labels)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WALKING'"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_labels[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
